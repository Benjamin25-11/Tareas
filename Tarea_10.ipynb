{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwOSIQ1wXm4RllhyjR3rqQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benjamin25-11/Tareas/blob/main/Tarea_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeaAhuBGmus9",
        "outputId": "7dd440ea-e337-4535-8bbc-d47cf3468517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from jax import grad, random\n",
        "from jax import jit\n",
        "import jax.numpy as jnp\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalizamos los datos\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Convertimos las imágenes a formato adecuado para el MLP\n",
        "train_images = jnp.array(train_images.reshape(-1, 28 * 28))\n",
        "test_images = jnp.array(test_images.reshape(-1, 28 * 28))\n",
        "train_labels = jnp.array(train_labels)\n",
        "test_labels = jnp.array(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "class_names[train_labels[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2bmbpfe7m0OZ",
        "outputId": "6080add1-a6b3-475f-b889-0e14cbc645b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ankle boot'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Función ReLU\n",
        "@jit\n",
        "def relu(z):\n",
        "    return jnp.maximum(0, z)\n",
        "\n",
        "# Función Softmax (para la salida de clasificación)\n",
        "@jit\n",
        "def softmax(z):\n",
        "    exp_z = jnp.exp(z)\n",
        "    return exp_z / jnp.sum(exp_z, axis=-1, keepdims=True)\n",
        "\n",
        "# Definir MLP con una capa oculta\n",
        "def mlp(params, x):\n",
        "    w1, b1, w2, b2, w3, b3 = params\n",
        "    # Capas ocultas\n",
        "    z1 = jnp.dot(x, w1) + b1\n",
        "    a1 = relu(z1)\n",
        "    z2 = jnp.dot(a1, w2) + b2\n",
        "    a2 = relu(z2)\n",
        "    # Capa de salida\n",
        "    z3 = jnp.dot(a2, w3) + b3\n",
        "    return softmax(z3)\n",
        "\n",
        "# Inicialización de pesos y sesgos\n",
        "def inicializar_pesos(rng, input_size, hidden_sizes, output_size):\n",
        "    w1 = random.normal(rng, (input_size, hidden_sizes[0])) * 0.01\n",
        "    b1 = jnp.zeros((hidden_sizes[0],))\n",
        "    w2 = random.normal(rng, (hidden_sizes[0], hidden_sizes[1])) * 0.01\n",
        "    b2 = jnp.zeros((hidden_sizes[1],))\n",
        "    w3 = random.normal(rng, (hidden_sizes[1], output_size)) * 0.01\n",
        "    b3 = jnp.zeros((output_size,))\n",
        "    return w1, b1, w2, b2, w3, b3\n",
        "\n",
        "# Definir los tamaños de la red\n",
        "input_size = 28 * 28  # Tamaño de la imagen aplanada\n",
        "hidden_sizes = [300, 100]  # Tamaño de las capas ocultas\n",
        "output_size = 10  # Número de clases\n",
        "\n",
        "# Inicializar parámetros\n",
        "rng = random.PRNGKey(0)\n",
        "params = inicializar_pesos(rng, input_size, hidden_sizes, output_size)"
      ],
      "metadata": {
        "id": "hJNOpgbRm_37"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de pérdida (Entropía Cruzada)\n",
        "@jit\n",
        "def cross_entropy_loss(params, x, y):\n",
        "    preds = mlp(params, x)\n",
        "    return -jnp.mean(jnp.sum(y * jnp.log(preds), axis=-1))\n",
        "\n",
        "# Función para calcular la precisión\n",
        "@jit\n",
        "def accuracy(params, x, y):\n",
        "    predictions = jnp.argmax(mlp(params, x), axis=1)\n",
        "    return jnp.mean(predictions == y)\n",
        "\n",
        "# Función de retropropagación y actualización de pesos\n",
        "@jit\n",
        "def actualizar_pesos(params, x, y, learning_rate=0.01):\n",
        "    # Calcular gradientes\n",
        "    grads = grad(cross_entropy_loss)(params, x, y)\n",
        "    # Actualizar los pesos\n",
        "    params = [w - learning_rate * dw\n",
        "              for w, dw in zip(params, grads)]\n",
        "    return params"
      ],
      "metadata": {
        "id": "x-bmiQ8ZnDzr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de pérdida para calcular la pérdida en test\n",
        "@jit\n",
        "def test_loss(params, x, y):\n",
        "    preds = mlp(params, x)\n",
        "    return -jnp.mean(jnp.sum(y * jnp.log(preds), axis=-1))\n",
        "\n",
        "# Configuración inicial\n",
        "epochs = 30\n",
        "learning_rate = 0.01\n",
        "batch_size = 64\n",
        "patience = 3  # Número de épocas sin mejora para detener\n",
        "accuracies = []\n",
        "losses = []\n",
        "\n",
        "# Inicialización para early stopping\n",
        "no_improvement_epochs = 0\n",
        "best_loss = float('inf')\n",
        "\n",
        "# Bucle de entrenamiento\n",
        "for epoch in range(epochs):\n",
        "    # Dividimos los datos en minibatches\n",
        "    num_batches = len(train_images) // batch_size\n",
        "    for i in range(num_batches):\n",
        "        x_batch = train_images[i * batch_size:(i + 1) * batch_size]\n",
        "        y_batch = jnp.eye(10)[train_labels[i * batch_size:(i + 1) * batch_size]]  # One-hot encoding\n",
        "\n",
        "        # Actualizar los pesos usando el gradiente\n",
        "        params = actualizar_pesos(params, x_batch, y_batch, learning_rate)\n",
        "\n",
        "    # Evaluar la pérdida y precisión en el conjunto de prueba\n",
        "    current_loss = test_loss(params, test_images, jnp.eye(10)[test_labels])\n",
        "    test_acc = accuracy(params, test_images, test_labels)\n",
        "    losses.append(current_loss)\n",
        "    accuracies.append(test_acc)\n",
        "    print(f'Época {epoch + 1}, Precisión en test: {test_acc:.3f}, Pérdida en test: {current_loss:.5f}')\n",
        "\n",
        "    # Monitoreo para early stopping\n",
        "    if jnp.abs(current_loss - best_loss) < 1e-2:  # Cambio menor a dos decimales\n",
        "        no_improvement_epochs += 1\n",
        "    else:\n",
        "        no_improvement_epochs = 0\n",
        "        best_loss = current_loss\n",
        "\n",
        "    # Condición para detener el entrenamiento\n",
        "    if no_improvement_epochs >= patience:\n",
        "        print(f\"Entrenamiento detenido temprano en la época {epoch + 1} debido a falta de mejora en la pérdida.\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDG6XZaynJUJ",
        "outputId": "bc262805-5a2b-4bd8-d78d-077435b6809b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 1, Precisión en test: 0.180, Pérdida en test: 2.27458\n",
            "Época 2, Precisión en test: 0.523, Pérdida en test: 1.23157\n",
            "Época 3, Precisión en test: 0.650, Pérdida en test: 0.91221\n",
            "Época 4, Precisión en test: 0.694, Pérdida en test: 0.83163\n",
            "Época 5, Precisión en test: 0.725, Pérdida en test: 0.75784\n",
            "Época 6, Precisión en test: 0.748, Pérdida en test: 0.68359\n",
            "Época 7, Precisión en test: 0.765, Pérdida en test: 0.63980\n",
            "Época 8, Precisión en test: 0.779, Pérdida en test: 0.61130\n",
            "Época 9, Precisión en test: 0.790, Pérdida en test: 0.58962\n",
            "Época 10, Precisión en test: 0.799, Pérdida en test: 0.57215\n",
            "Época 11, Precisión en test: 0.804, Pérdida en test: 0.55717\n",
            "Época 12, Precisión en test: 0.810, Pérdida en test: 0.54361\n",
            "Época 13, Precisión en test: 0.814, Pérdida en test: 0.53091\n",
            "Época 14, Precisión en test: 0.818, Pérdida en test: 0.51917\n",
            "Época 15, Precisión en test: 0.820, Pérdida en test: 0.50874\n",
            "Época 16, Precisión en test: 0.823, Pérdida en test: 0.49914\n",
            "Época 17, Precisión en test: 0.827, Pérdida en test: 0.49049\n",
            "Época 18, Precisión en test: 0.830, Pérdida en test: 0.48161\n",
            "Época 19, Precisión en test: 0.834, Pérdida en test: 0.47393\n",
            "Época 20, Precisión en test: 0.837, Pérdida en test: 0.46613\n",
            "Época 21, Precisión en test: 0.840, Pérdida en test: 0.45914\n",
            "Época 22, Precisión en test: 0.842, Pérdida en test: 0.45273\n",
            "Época 23, Precisión en test: 0.844, Pérdida en test: 0.44704\n",
            "Época 24, Precisión en test: 0.846, Pérdida en test: 0.44201\n",
            "Época 25, Precisión en test: 0.847, Pérdida en test: 0.43719\n",
            "Época 26, Precisión en test: 0.849, Pérdida en test: 0.43316\n",
            "Época 27, Precisión en test: 0.850, Pérdida en test: 0.42926\n",
            "Época 28, Precisión en test: 0.851, Pérdida en test: 0.42569\n",
            "Época 29, Precisión en test: 0.852, Pérdida en test: 0.42190\n",
            "Época 30, Precisión en test: 0.853, Pérdida en test: 0.41866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NfLD6l8Jn9Cl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}